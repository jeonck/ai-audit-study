# AI 유형별 신뢰성 시험평가 범위 (4대 시험 영역 포함)

AI 시스템의 신뢰성 시험평가 범위는 AI의 유형, 자율성 정도, 그리고 활용 환경에 따라 달라집니다. 모든 AI 유형은 기본적으로 상호작용, 보안성, 안전성, 효과성의 4대 핵심 영역을 평가받아야 하며, 시스템의 복잡도가 높아질수록 각 영역의 평가 범위가 심층적으로 확대됩니다. 🛡️

## 1. 전통적 머신러닝 및 판별 AI (Traditional & Discriminative AI)

**유형**: 데이터 분류(Classification), 예측(Prediction) 등 결과를 판별하는 AI. (예: 스팸 필터, 대출 심사 스코어링)

| 시험 영역 | 중점 평가 범위 | 주요 위험 요소 |
|-----------|----------------|----------------|
| **효과성 (Performance)** | 정확도, 정밀도, 재현율, F1 점수 등 성능 지표. | 낮은 예측 정확도로 인한 비즈니스적 손실 (오탐/미탐). |
| **보안성 (Security)** | 데이터 포이즌 공격 방어 능력, 모델 추출 공격 취약점. | 모델 복제 및 무단 학습 데이터 기밀성 침해. |
| **안전성 (Safety)** | 편향성 분석 (공정성 평가), 설명 가능성(XAI). | 특정 그룹에 대한 차별적 의사결정, 법적/윤리적 규제 위반. |
| **상호작용 (Interaction)** | **사용자 인터페이스(UI)**의 명확성, 결과 제시의 투명성. | 사용자가 AI 결과에 대한 신뢰도를 상실하거나 오해할 위험. |

## 2. 생성형 AI (Generative AI, GenAI / LLM)

**유형**: 텍스트, 이미지 등 새로운 콘텐츠를 생성하거나 복잡한 추론을 수행하는 AI. (예: Claude, ChatGPT)

| 시험 영역 | 중점 평가 범위 | 주요 위험 요소 |
|-----------|----------------|----------------|
| **효과성 (Performance)** | 진실성(Factuality), 환각률(Hallucination Rate), 추론 능력 벤치마크 (MMLU 등). | 사실이 아닌 정보를 생성하여 사용자에게 잘못된 지식을 전달. |
| **보안성 (Security)** | 프롬프트 인젝션 방어, 악의적 코드 생성 능력 (사이버 보안 위험). | AI 모델을 통한 사이버 공격 실행 또는 내부 시스템 접근 권한 획득 유도. |
| **안전성 (Safety)** | 레드팀 구성을 통한 유해성 콘텐츠 생성 테스트 (CBRN, 불법 정보). 일관성 및 정렬성(Alignment). | 악의적 오용(Misuse) 위험, 사회적 안전 위협. |
| **상호작용 (Interaction)** | 대화의 일관성 및 맥락 유지, 사용자 피드백 반영 능력, 응답 거부 메커니즘의 적절성. | 사용자의 부정확한 피드백을 학습하거나, 유해한 명령에 대해 명확히 거부하지 못하는 위험. |

## 3. 에이전트 AI (Agentic AI)

**유형**: 스스로 목표를 설정, 계획하고, 외부 도구를 사용하며 자율적인 행동을 수행하는 AI. (예: 자율 에이전트, AI 비서)

| 시험 영역 | 중점 평가 범위 | 주요 위험 요소 |
|-----------|----------------|----------------|
| **효과성 (Performance)** | 장기 목표 달성률, 도구 사용의 효율성 및 정확성, 오류 발생 시 재계획 능력. | 복잡한 작업 중 비효율적인 경로 선택 또는 반복 루프에 빠져 작업 실패. |
| **보안성 (Security)** | 외부 API 및 시스템 접근 통제 (권한 탈취), 자체 코드 생성 및 실행의 보안성. | 에이전트가 부여된 권한을 넘어 다른 시스템에 무단 접근하여 데이터 유출. |
| **안전성 (Safety)** | 자율성 및 통제력 상실 평가, 인간 개입 지점(Human Veto Points) 검증, 일탈 행위(Deception) 테스트. | 에이전트가 최종 목표를 벗어나거나, 통제를 회피하는 의도치 않은 행동 수행. |
| **상호작용 (Interaction)** | 계획 단계의 투명성, 사용자 피드백에 따른 목표 수정 능력, 작업 상태 실시간 보고. | AI의 자율적인 행동에 대해 사용자가 예측하거나 이해하지 못하는 '블랙박스' 문제. |

## 4. 피지컬 AI 및 자율 시스템 (Physical & Autonomous Systems)

**유형**: 물리적 세계와 상호작용하며 자율적으로 목표를 달성하는 시스템. (예: 자율주행차, 산업용 로봇)

| 시험 영역 | 중점 평가 범위 | 주요 위험 요소 |
|-----------|----------------|----------------|
| **효과성 (Performance)** | 센서 융합 정확도, 실시간 경로 계획 성공률, **희소 상황(Edge Cases)**에서의 인식 오류율. | AI 오작동으로 인한 물리적 환경에서의 효율성 저하 및 임무 실패. |
| **보안성 (Security)** | 통신 채널 암호화, 센서 데이터 변조에 대한 취약성, 모델 추출/변조 공격 방어. | 외부 공격으로 인한 로봇의 통제권 탈취나 자율주행차의 운행 조작 위험. |
| **안전성 (Safety)** | 기능 안전(Functional Safety) 준수 (ISO 26262 등), 페일 세이프 및 비상 정지 메커니즘, 물리적 충돌 방지. | AI 오작동으로 인한 인명 피해나 재산 손실 등 직접적인 물리적 해악. |
| **상호작용 (Interaction)** | **인간-기계 상호작용(HMI)**의 명확성, 로봇의 의도 표시(예: 이동 방향 예측), 위험 고지. | 로봇의 행동이 예측 불가능하여 주변 인간 작업자의 안전을 위협하는 상황. |

## 5. 전반적인 거버넌스 및 관리 시스템 (Governance & Management)

AI 유형과 관계없이 모든 고영향 AI 시스템에 공통적으로 적용되어야 할 평가 범위입니다.

| 시험 영역 | 중점 범위 | 표준 프레임워크 |
|-----------|-----------|-----------------|
| **효과성** | ISO/IEC 42001에 따른 AIMS의 지속적인 개선 능력, 목표 달성도 평가. | AI 경영 시스템의 전략적 효과와 운영 효율성 확보. |
| **보안성** | ISO/IEC 27001 등 정보보호 표준 준수, 공급망 보안 관리. | AI 자산과 데이터의 기밀성, 무결성, 가용성 유지. |
| **안전성** | ISO/IEC 23894 기반의 위험 관리 프로세스 충실성, AI 영향 평가(AIA) 수행. | AI 위험 관리에 대한 법적 및 윤리적 준수 책임 확보. |
| **상호작용** | ISO/IEC 38507 기반의 거버넌스 원칙 준수, 투명성 정책 이행. | 모든 이해관계자와의 신뢰 구축 및 책임성(Accountability) 확보. |