# AI 관련 표준 및 가이드라인 통합 뷰

인공지능(AI)의 발전에 따라 국제 조직과 각국은 AI 시스템의 안전성, 신뢰성, 윤리성을 확보하기 위한 다양한 표준 및 가이드라인을 제정하고 있습니다. 이 문서는 주요 AI 관련 표준과 가이드라인의 체계적인 개요를 제공합니다.

## 📚 국제 표준 (ISO/IEC)

### 1. AI 개념 및 용어: ISO/IEC 22989:2022

| 항목 | 내용 |
|------|------|
| **명칭** | ISO/IEC 22989:2022 - Information technology — Artificial intelligence — Concepts and terminology |
| **발행 기관** | 국제 표준화 기구 (ISO) 및 국제 전기기술 위원회 (IEC) |
| **기술 위원회** | ISO/IEC JTC 1/SC 42 (인공지능) |
| **근거** | AI 분야의 공통 언어 확립을 위한 기본 표준으로, 이후 개발되는 모든 AI 관련 표준의 용어적 기반을 제공합니다. |
| **한국 표준 (참고)** | KS X ISO/IEC 22989 (국가기술표준원 부합화) |

### 2. AI 위험 관리: ISO/IEC 23894:2023

| 항목 | 내용 |
|------|------|
| **명칭** | ISO/IEC 23894:2023 - Information technology — Artificial intelligence — Guidance on risk management |
| **발행 기관** | 국제 표준화 기구 (ISO) 및 국제 전기기술 위원회 (IEC) |
| **기술 위원회** | ISO/IEC JTC 1/SC 42 (인공지능) |
| **근거** | AI의 특성을 고려하여 ISO 31000 (위험 관리) 원칙을 AI 시스템의 전 수명 주기에 적용하도록 돕는 지침(Guidance) 표준입니다. |
| **참고 표준** | ISO 31000 (Risk Management) |

### 3. AI 신뢰성: ISO/IEC 24028:2020

| 항목 | 내용 |
|------|------|
| **명칭** | ISO/IEC TR 24028:2020 - Information technology — Artificial intelligence — Guidelines for addressing trustworthiness in AI |
| **발행 기관** | 국제 표준화 기구 (ISO) 및 국제 전기기술 위원회 (IEC) |
| **기술 위원회** | ISO/IEC JTC 1/SC 42 (인공지능) |
| **근거** | AI 시스템의 신뢰성을 구성하는 7가지 핵심 속성과, 해당 속성을 확보하기 위한 기술적 및 조직적 접근 방식을 논의하는 **기술 보고서 (Technical Report, TR)**입니다. |
| **목표** | AI의 윤리적 원칙을 기술적인 요구사항 및 위험 완화와 연계합니다. |

### 4. AI 경영 시스템 인증: ISO/IEC 42001:2023

| 항목 | 내용 |
|------|------|
| **명칭** | ISO/IEC 42001:2023 - Information technology — Artificial intelligence — Management system |
| **발행 기관** | 국제 표준화 기구 (ISO) 및 국제 전기기술 위원회 (IEC) |
| **기술 위원회** | ISO/IEC JTC 1/SC 42 (인공지능) |
| **근거** | 조직이 AI 시스템의 책임 있는 개발 및 사용을 위해 경영 시스템을 구축하고 인증받을 수 있도록 하는 요구사항 표준입니다. 최초의 AI 전용 경영 시스템 인증 표준입니다. |
| **구조** | 다른 경영 시스템 표준과 동일한 **HLS (High-Level Structure)**를 따릅니다. |

## 📜 유럽연합(EU) AI 윤리 및 감사 관련

### 5. EU 신뢰할 수 있는 AI 윤리 가이드라인: EU Ethics Guidelines for Trustworthy AI (2019)

| 항목 | 내용 |
|------|------|
| **명칭** | Ethics Guidelines for Trustworthy AI |
| **발행 기관** | 유럽 연합 집행위원회 (European Commission) 산하 AI 고위 전문가 그룹 (High-Level Expert Group on AI, HLEG) |
| **발행 연도** | 2019년 4월 |
| **근거** | EU AI 법 (AI Act) 제정의 토대가 된 핵심 정책 문서로, AI가 준수해야 할 **3가지 핵심 요소 (합법성, 윤리성, 견고성)**와 이를 실현하기 위한 7가지 핵심 요구사항을 제시합니다. |

### 6. EU ALTAI (Assessment List for Trustworthy AI)

| 항목 | 내용 |
|------|------|
| **명칭** | Assessment List for Trustworthy AI (ALTAI) |
| **발행 기관** | 유럽 연합 집행위원회 (European Commission) 산하 AI 고위 전문가 그룹 (HLEG) |
| **근거** | 윤리 가이드라인의 7가지 요구사항을 실무적으로 점검하고 문서화하기 위한 체크리스트/평가 목록입니다. EU AI 법의 문서화 의무를 이행하는 데 실질적인 도움을 줍니다. |

## 🏛️ AI 감사 및 감시 관련

### 7. IIA AI 감사 프레임워크: The IIA AI Auditing Framework

| 항목 | 내용 |
|------|------|
| **명칭** | Artificial Intelligence Auditing Framework |
| **발행 기관** | IIA (The Institute of Internal Auditors) |
| **근거** | 내부 감사인이 AI 시스템의 거버넌스, 위험, 통제에 대해 독립적인 보증 및 자문을 제공할 수 있도록 돕는 전문 지침입니다. 내부 감사 직무 표준에 따라 AI 리스크 평가의 필요성을 강조합니다. |
| **핵심 분류** | 3가지 상위 구성 요소 (AI 전략, 거버넌스, 인적 요소)와 7가지 핵심 요소를 제시합니다. |

## 🔄 상호 연계성 및 활용

이러한 표준과 가이드라인들은 서로 밀접하게 연계되어 있습니다:

- **ISO/IEC 22989**는 기반 용어 표준으로, 다른 모든 AI 관련 표준의 언어를 통일하는 역할을 합니다.
- **ISO/IEC 23894**는 ISO 31000의 원칙을 AI에 적용하여 위험 관리의 구체적인 방법을 제시합니다.
- **ISO/IEC 24028**은 신뢰성을 구성하는 기술적 속성을 설명하고, **ISO/IEC 42001**은 이를 조직적인 경영 시스템으로 확보하는 방법을 제시합니다.
- **EU 윤리 가이드라인**은 정책적 기반을 제공하고, **ALTAI**는 실무적인 자체 점검 도구로 사용됩니다.
- 이러한 국제 표준과 EU 가이드라인은 각국의 법제화 및 감사 프레임워크에 반영되고 있습니다.

이러한 표준과 가이드라인들은 조직이 책임 있는 AI 개발 및 사용을 보장하는 데 중요한 기반을 형성합니다.