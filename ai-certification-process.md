# 인공지능 신뢰성 인증 준비 절차

인공지능 신뢰성 인증을 위한 준비 절차는 국제표준 ISO/IEC 42001 (AI 경영 시스템) 및 **ISO/IEC 23894 (AI 위험 관리)**에서 제시하는 **위험 관리 프로세스(Risk Management Process)**를 기반으로 합니다. 이 절차는 AI 시스템의 전 수명 주기 동안 위험을 식별하고 통제함으로써 궁극적으로 시스템의 신뢰성을 확보하는 데 중점을 둡니다.

준비 절차는 다음 6단계로 정리될 수 있습니다.

## 1. 위험 인식 (Risk Identification & Context Establishment)

이 단계는 AI 시스템의 **운영 맥락(Context)**을 설정하고, 시스템이 내포하거나 초래할 수 있는 **잠재적 위험원(Risk Sources)**을 최초로 식별하는 과정입니다.

- **시스템 맥락 설정**: AI 시스템의 목적, 의도된 사용 환경, 기술적 구성 요소, 그리고 사용자 및 이해관계자를 명확히 정의합니다. 이는 위험 평가의 기준이 됩니다.

- **위험원 식별**: AI 시스템에 고유한 위험원을 체계적으로 식별합니다. 여기에는 다음이 포함됩니다.
  - **기술적 위험**: 데이터 편향, 모델 드리프트, 모델 견고성 부족, 사이버 보안 취약점.
  - **운영적 위험**: 데이터 거버넌스 부재, 시스템 오류 시 인간 개입의 어려움.
  - **윤리적/사회적 위험**: 차별(공정성 위반), 투명성 부족, 책임 소재 불분명.

- **이해관계자 협의**: 이해관계자(개발자, 사용자, 법률 전문가 등)와의 협의를 통해 위험에 대한 인식 수준과 관점을 통일합니다.

## 2. 목표 설정 (Goal Setting & Trustworthiness Definition)

AI 시스템을 통해 달성해야 할 신뢰성 수준과 목표를 정의하고 문서화하는 단계입니다.

- **신뢰성 속성 정의**: 조직의 정책과 AI 시스템의 사용 맥락에 맞춰 공정성, 투명성, 안전성, 견고성, 책임성 등 핵심 신뢰성 속성의 정의와 목표 수준을 설정합니다.
  - 예: 공정성 목표는 '성별에 따른 대출 승인률 차이(Disparate Impact)가 10% 미만'으로 정의.

- **인증 범위 설정**: 인증을 받고자 하는 AI 시스템의 범위와 **적용할 표준(예: ISO/IEC 42001, ISO/IEC 23894)**을 명확히 합니다.

- **경영진 의지 표명**: 최고 경영진은 신뢰성 목표 달성을 위한 자원 할당 및 리더십을 명확히 하고, 이를 AI 정책으로 선언합니다.

## 3. 위험 분석 (Risk Analysis)

식별된 각 위험원이 발생할 경우의 **영향(Impact)**과 **발생 가능성(Likelihood)**을 상세히 분석하는 단계입니다.

- **영향 분석**: 위험이 발생했을 때 조직, 사용자, 사회에 미칠 수 있는 피해의 심각도를 정량적/정성적으로 평가합니다 (예: 재정 손실, 법적 제재, 인명 피해, 평판 손상).

- **발생 가능성 분석**: 해당 위험원이 실제로 발생할 확률을 분석합니다 (예: 과거 데이터, 시스템 복잡도, 공격 환경 등을 고려).

- **위험 수준 결정**: 영향과 발생 가능성을 곱하거나 조합하여 각 위험원의 **내재적 위험 수준(Inherent Risk Level)**을 결정합니다.

## 4. 위험 평가 (Risk Evaluation)

분석된 위험 수준을 조직이 **허용할 수 있는 기준(Risk Criteria)**과 비교하여 위험 처리의 우선순위를 결정하는 단계입니다.

- **위험 기준 정의**: 조직이 **감수할 수 있는 최대 허용 위험 수준(Acceptable Risk Level)**을 미리 설정합니다. 이는 법적 요구 사항, 산업 표준, 조직의 위험 선호도 등을 반영합니다.

- **우선순위 결정**: 내재적 위험 수준이 허용 기준을 초과하는 위험(Tolerable Risk)을 '높음', '중간', '낮음' 등으로 분류하고, 가장 높은 위험부터 처리 대상 목록에 올립니다.

- **잔여 위험 예측**: 위험 처리(완화) 계획이 실행된 후 남을 것으로 예상되는 **잔여 위험(Residual Risk)**을 예측하고, 이 역시 허용 기준 내에 있는지 확인합니다.

## 5. 처리 계획 수립 (Risk Treatment Planning)

위험 평가를 통해 결정된 우선순위에 따라 위험을 통제하고 완화하기 위한 구체적인 실행 계획을 수립하는 단계입니다.

- **통제 항목 선정**: ISO/IEC 42001 부속서 A 등 AI 특정 통제 항목(Controls) 목록을 검토하여, 식별된 위험을 완화하는 데 가장 효과적인 통제 항목을 선정합니다.

- **처리 옵션 결정**: 위험을 회피(Avoidance), 경감(Mitigation), 공유(Sharing), 수용(Acceptance) 중 어떤 방법으로 처리할지 결정합니다. 대부분의 경우 **경감(통제 구현)**이 선택됩니다.

- **실행 계획 및 자원 할당**: 각 통제 항목을 구현하는 데 필요한 활동, 책임자, 시간표, 예산을 명확하게 정의하고 자원을 할당합니다.

## 6. 위험 관리 및 모니터링 (Risk Management & Monitoring)

처리 계획에 따라 통제 항목을 구현하고, AI 시스템의 운영 수명 주기 동안 위험 상태를 지속적으로 감시하고 관리하는 단계입니다.

- **통제 구현 및 운영**: 선정된 통제 항목(예: 데이터 편향성 검사 도구, 인간 개입 절차)을 시스템에 통합하고 운영합니다.

- **성과 측정 및 모니터링**: 구현된 통제가 **예상대로 위험을 완화했는지(잔여 위험)**를 정기적으로 측정하고, AI 시스템의 성능(모델 드리프트) 및 **새로운 위협(Emerging Risks)**을 지속적으로 모니터링합니다.

- **경영진 검토**: 최소 연 1회 경영진은 위험 관리 시스템의 적절성, 충분성, 효과성을 검토하고 개선 방향을 지시합니다. 이 검토 결과는 ISO/IEC 42001 인증 유지의 핵심 증거 자료가 됩니다.

## 키워드
- 인공지능
- 신뢰성 인증
- ISO/IEC 42001
- ISO/IEC 23894
- 위험 관리
- AI 경영 시스템
- AI 수명 주기
- 위험 식별
- 위험 분석
- 위험 평가
- 위험 처리
- 위험 모니터링
- AI 신뢰성
- 공정성
- 투명성
- 안전성
- 견고성
- 책임성
- AI 정책
- 통제 항목