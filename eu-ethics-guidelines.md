# EU 신뢰할 수 있는 인공지능 윤리 가이드라인

EU 집행위원회(European Commission)가 2019년에 발표한 **'신뢰할 수 있는 인공지능을 위한 윤리 가이드라인 (Ethics Guidelines for Trustworthy AI)'**은 유럽 연합의 AI 정책 및 규제의 토대가 된 핵심 문서입니다.

이 가이드라인은 AI 시스템이 유럽 사회에 통합될 때 존중되어야 할 세 가지 핵심 요소와 이를 실현하기 위한 일곱 가지 핵심 요구사항을 제시합니다.

## EU 신뢰할 수 있는 AI (Trustworthy AI)의 3가지 핵심 요소

EU는 AI가 신뢰할 수 있도록 하기 위해서는 다음 세 가지 요소가 동시에 충족되어야 한다고 명시합니다.

- **합법적(Lawful)**: AI는 모든 관련 법률과 규정을 준수해야 합니다. (예: 개인정보보호 규정 GDPR, 소비자 보호법 등)

- **윤리적(Ethical)**: AI는 확립된 윤리적 원칙과 가치를 준수해야 합니다.

- **견고한(Robust)**: AI는 기술적으로 견고하고 신뢰할 수 있어야 하며, 의도하지 않은 해를 끼치지 않도록 설계되어야 합니다.

## 7가지 핵심 요구사항 (Key Requirements)

신뢰할 수 있는 AI를 실현하기 위해 AI 시스템의 전 수명 주기(Lifecycle)에 걸쳐 충족되어야 할 실질적인 요구사항들입니다.

### 1. 인간의 주도성 및 감독 (Human Agency and Oversight)

- **목표**: AI 시스템이 자율적으로 운영되더라도, 인간이 항상 최종적인 통제권을 가지며 자율성을 유지할 수 있도록 보장해야 합니다.

- **실천**: 'Human-in-the-loop(인간 개입)', 'Human-on-the-loop(인간 감독)', 'Human-in-command(인간 통제)'와 같은 접근 방식을 통해 인간의 적절한 감독을 보장합니다.

### 2. 기술적 견고성 및 안전성 (Technical Robustness and Safety)

- **목표**: AI 시스템은 신뢰할 수 있고, 안전하며, 오류나 예상치 못한 상황에 대해 **복원력(Resilience)**을 갖춰야 합니다.

- **실천**: 강건성(Robustness), 정확성(Accuracy), 신뢰성(Reliability), **안전성(Safety)**을 확보하고, 적대적 공격(Adversarial Attacks)으로부터 시스템을 보호해야 합니다.

### 3. 프라이버시 및 데이터 거버넌스 (Privacy and Data Governance)

- **목표**: AI 시스템이 사용되는 전 과정에서 데이터의 품질과 무결성을 보장하며, 개인의 프라이버시를 존중해야 합니다.

- **실천**: **GDPR(일반 데이터 보호 규정)**을 준수하며, 설계에 의한 프라이버시(Privacy by Design) 원칙을 적용하고, 데이터 접근 통제를 철저히 해야 합니다.

### 4. 투명성 (Transparency)

- **목표**: AI 시스템의 작동 방식, 데이터 처리 방식, 그리고 시스템의 결정이 어떻게 내려졌는지에 대해 이해관계자들에게 명확하게 소통되어야 합니다.

- **실천**:
  - **추적성(Traceability)**: 시스템 작동 과정과 결과를 기록하고 추적할 수 있어야 합니다.
  - **설명 가능성(Explainability)**: AI 결정의 근거를 인간이 이해할 수 있는 형태로 제공해야 합니다.
  - **의사소통(Communication)**: AI 시스템이 관여하고 있다는 사실을 사용자에게 알려야 합니다.

### 5. 다양성, 비차별 및 공정성 (Diversity, Non-discrimination and Fairness)

- **목표**: AI 시스템의 개발 및 사용이 모든 개인과 집단에게 공정하고 공평한 기회를 제공해야 하며, 불필요하거나 불법적인 편향(Bias)을 유발해서는 안 됩니다.

- **실천**: 개발 데이터에 존재하는 편향을 식별하고 완화하며, 설계 단계에서부터 접근성(Accessibility)을 고려하여 시스템이 모든 사용자에게 공정하게 접근 가능하도록 해야 합니다.

### 6. 사회적 및 환경적 웰빙 (Societal and Environmental Well-being)

- **목표**: AI 시스템은 사회에 긍정적인 영향을 미치고 지속 가능한 발전을 지원해야 합니다.

- **실천**: 시스템이 환경적 지속 가능성에 기여하고, 민주주의, 법치주의, 그리고 사회적 조화를 강화하도록 설계되어야 합니다.

### 7. 책임성 (Accountability)

- **목표**: AI 시스템의 결과를 책임질 주체를 명확히 하고, 해당 결과를 감사하고(Auditable) 보고할 수 있도록 해야 합니다.

- **실천**: AI 시스템에 대한 감사(Audit) 및 평가 프로세스를 마련하고, 잠재적인 부정적 결과에 대한 구제 수단을 보장해야 합니다.

이 가이드라인은 이후 발표된 **EU AI 법(AI Act)**의 **위험 기반 접근 방식(Risk-Based Approach)**의 기초가 되었으며, 특히 **고위험 AI(High-Risk AI)**에 대한 규제 요건을 설정하는 데 큰 영향을 미쳤습니다.