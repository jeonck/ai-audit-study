# 인공지능 안정성, 신뢰성 확보 방안 및 검인증 소개

## 인공지능 기본법 소개

'인공지능 발전과 신뢰 기반 조성 등에 관한 기본법'은 대한민국에서 인공지능(AI)의 건전한 발전과 신뢰 기반 조성을 위한 기본적인 사항을 규정하는 법률입니다. 일반적으로 'AI 기본법'으로 불리며, 국민의 권익과 존엄성을 보호하고 국가경쟁력 강화를 목적으로 합니다. 🇰🇷

### 주요 제정 및 시행 정보
- **제정일**: 2025년 1월 21일 (법률 제20676호)
- **국회 의결**: 2024년 12월 26일
- **시행 예정일**: 2026년 1월 22일 (일부 조항 제외)

### 주요 내용 및 목표
이 법은 AI 기술 발전 지원과 함께 AI가 사회에 미치는 위험을 예방하고 신뢰성을 확보하는 데 중점을 두고 있습니다.

#### 1. AI 발전 및 산업 육성 지원
- **인공지능기본계획 수립**: 정부는 3년마다 국가 AI 경쟁력 강화를 위한 인공지능기본계획을 수립하고 시행합니다.
- **국가인공지능위원회 운영**: 대통령을 위원장으로 하고 민간위원이 과반을 구성하는 국가인공지능위원회의 법적 근거를 마련하여 AI 정책을 민간 주도로 추진합니다.
- **R&D 및 인프라 지원**: AI 연구개발 지원, 표준화, 학습용 데이터 시책 수립, AI 데이터센터 구축 및 운영 등 AI 산업 육성을 위한 정부 지원의 근거를 마련합니다.

#### 2. AI 신뢰 기반 조성 및 위험 관리
- **AI 안전 및 신뢰성 확보 의무**: AI 사업자는 인공지능의 안전성과 신뢰성을 확보하기 위해 위험 식별·평가 및 완화 조치를 이행하고 위험관리체계를 구축해야 합니다.
- **고영향 인공지능 규정**: 사람의 생명, 신체 안전, 기본권에 중대한 영향을 미치는 AI 시스템을 '고영향 인공지능'으로 분류하고, 이를 제공하는 사업자에게는 안전 확보 조치 이행 및 그 근거 문서를 보관하고 위험관리방안을 공개하도록 책무를 부과합니다.
- **주요 적용 분야**: 의료기기, 에너지/수도 공급, 교통시설 운영, 채용·대출 심사, 공공서비스 자격확인 및 의사결정, 학생 평가 등.
- **투명성 확보 의무**: AI 사업자는 이용자가 인공지능을 통해 생성된 결과물임을 알 수 있도록 고지 또는 표시해야 하며, 주된 이용자의 연령, 신체적 조건 등을 고려해야 합니다.
- **AI 윤리 원칙**: AI의 개발·활용 과정에서 사람의 생명, 신체, 정신적 건강 등에 해가 되지 않는 안전성과 신뢰성, 모든 사람이 자유롭고 편리하게 이용할 수 있는 접근성 등 AI 윤리 원칙에 관한 시책을 마련하도록 합니다.

### 이 법의 의의
AI 기본법의 제정은 우리나라가 EU에 이어 세계에서 두 번째로 AI 관련 국가 차원의 거버넌스 체계를 법적으로 정립하고, AI 산업 육성과 함께 AI 위험의 사전 예방 및 신뢰성 확보를 위한 기반을 마련했다는 점에서 큰 의미가 있습니다.

이러한 법적 근거를 바탕으로 AI 기술의 혁신적인 발전과 사회적 책임 및 윤리적 활용의 균형을 맞추는 것이 목표입니다.

## 인공지능 안전성 확보 의무 (제32조)

'인공지능 발전과 신뢰 기반 조성 등에 관한 기본법' 제32조는 인공지능 안전성 확보 의무에 관한 내용을 담고 있으며, 특히 대규모 인공지능 시스템을 다루는 사업자에게 특정한 책무를 부과합니다. 🛡️

### 인공지능 기본법 제32조 (인공지능 안전성 확보 의무) 주요 내용
제32조는 AI 사업자가 일정 기준 이상의 인공지능 시스템에 대해 안전성 확보 조치를 이행하고 그 결과를 정부에 제출하도록 규정하고 있습니다.

#### 1. 의무 대상 (제32조제1항)
- **대상**: 학습에 사용된 누적 연산량이 대통령령으로 정하는 기준 이상인 인공지능 시스템 (소위 대규모 인공지능 또는 거대 AI)을 제공하는 인공지능사업자입니다.

- **참고**: 대통령령(시행령)에서는 구체적인 연산량 기준을 정하며, 현재 논의 중인 시행령(안)에 따르면 이 기준은 10의 26승 부동소수점 연산(FLOPs) 이상인 시스템 등인 것으로 알려져 있습니다.

#### 2. 사업자가 이행해야 할 사항 (제32조제1항 각 호)
의무 대상 인공지능사업자는 시스템의 안전성을 확보하기 위해 다음 두 가지 조치를 이행해야 합니다.

1. **위험의 식별ㆍ평가 및 완화**:
   - 인공지능 시스템의 수명주기 전반에 걸쳐 발생할 수 있는 위험을 식별, 평가하고, 이를 완화하기 위한 조치를 취해야 합니다.

2. **위험관리체계 구축**:
   - 인공지능 관련 안전사고를 모니터링하고, 사고 발생 시 적절하게 대응할 수 있는 위험관리체계를 구축해야 합니다.

#### 3. 이행 결과 제출 의무 (제32조제2항)
- 인공지능사업자는 위 제1항 각 호에 따른 안전성 확보 조치 이행 결과를 과학기술정보통신부장관에게 제출해야 합니다.

### 제32조의 의미와 중요성
제32조는 AI 기본법 내에서 AI 안전 및 신뢰성 확보를 위한 핵심적인 규정 중 하나입니다.

- **책임 주체 명확화**: 대규모 AI 모델을 개발하고 운영하는 사업자에게 선제적인 안전 확보 의무를 부과하여 사회적 위험을 최소화하려는 목적을 가집니다.

- **사전적 규제**: AI가 야기할 수 있는 사고를 사후적으로 처리하는 것이 아니라, AI 시스템이 개발 및 운영되는 수명주기 전반에서 위험을 미리 관리하도록 강제합니다.

- **고영향 AI 규제와의 관계**: 제32조에서 규정하는 대규모 AI에 대한 안전성 확보 의무는 제34조의 고영향 인공지능에 대한 사업자의 책무와는 별개로 적용될 수 있으며, 두 가지 의무 모두를 준수해야 하는 경우도 발생할 수 있습니다. (예: 대규모 AI이면서 동시에 고영향 AI인 경우)

## 고영향 인공지능의 확인 (제33조)

'인공지능 발전과 신뢰 기반 조성 등에 관한 기본법' 제33조는 고영향 인공지능의 확인에 관한 조항으로, 인공지능 사업자에게 사전 검토 의무를 부과하는 것이 핵심입니다.

### 인공지능 기본법 제33조 (고영향 인공지능의 확인) 주요 내용
제33조는 인공지능 사업자가 자신이 제공하는 AI 시스템이 고영향 인공지능에 해당하는지 여부를 스스로 확인하고, 필요한 경우 정부의 도움을 받을 수 있도록 규정합니다.

#### 1. 사전 검토 의무 (제33조제1항)
- **의무 주체**: 인공지능 또는 이를 이용한 제품·서비스를 제공하는 인공지능사업자
- **의무 내용**: 사업자는 자신이 제공하는 인공지능이 고영향 인공지능에 해당하는지에 대하여 사전에 검토하여야 합니다.

📌 **고영향 인공지능이란?**
- 사람의 생명, 신체 안전, 기본권에 중대한 영향을 미치는 인공지능 시스템으로, 이 법에서 가장 높은 수준의 **책무(제34조)**가 부과되는 AI를 의미합니다. (예: 채용·대출 심사, 범죄 수사/체포 목적의 생체인식 활용 등)

#### 2. 확인 요청 (제33조제1항)
- 인공지능사업자는 사전 검토 후에도 필요하다고 판단하는 경우, 과학기술정보통신부장관에게 해당 인공지능이 고영향 인공지능에 해당하는지 여부의 확인을 요청할 수 있습니다.

#### 3. 확인 절차의 규정 (제33조제2항)
- 고영향 인공지능의 확인 기준, 확인 절차, 그 밖에 필요한 사항은 대통령령으로 정합니다.

### 제33조의 역할과 의의
제33조는 사업자 스스로 책임 있는 AI 개발·활용을 유도하는 자율 규제와 정부 지원의 연결고리 역할을 합니다.

- **자율적 책임**: 사업자가 스스로 위험 수준을 판단하여 제34조의 엄격한 책무(위험관리, 설명, 문서화 등)를 이행할 준비를 하도록 의무를 부여합니다.

- **불확실성 해소**: 사업자가 판단하기 어려운 경우, 정부(과학기술정보통신부장관)에 확인을 요청하여 규제 대상 여부의 불확실성을 해소하고 예측 가능성을 높일 수 있도록 지원합니다.

- 이는 AI의 혁신을 저해하지 않으면서도, 국민의 안전과 권익을 보호해야 하는 핵심적인 AI 시스템에 대한 규제 집행의 시작점이 되는 조항입니다.

- 고영향 인공지능의 확인 절차 등에 관하여 필요한 사항은 현재 시행령으로 구체화될 예정입니다.

## 고영향 인공지능과 관련한 사업자의 책무 (제34조)

'인공지능 발전과 신뢰 기반 조성 등에 관한 기본법' 제34조는 **고영향 인공지능(High-Impact AI)**을 제공하는 인공지능사업자에게 안전성 및 신뢰성 확보를 위한 구체적인 책무를 부과하는 핵심 조항입니다. 🚨⚖️

### 인공지능 기본법 제34조 (고영향 인공지능과 관련한 사업자의 책무) 주요 내용
제34조는 고영향 인공지능(사람의 생명, 신체 안전, 기본권에 중대한 영향을 미치는 AI 시스템)을 이용한 제품·서비스를 제공하는 사업자가 반드시 이행해야 할 조치들을 규정합니다.

#### 1. 의무 대상
- 고영향 인공지능 또는 이를 이용한 제품ㆍ서비스를 제공하는 인공지능사업자

#### 2. 사업자가 이행해야 할 안전성ㆍ신뢰성 확보 조치 (제34조제1항 각 호)
고영향 인공지능사업자는 대통령령으로 정하는 바에 따라 다음 각 호의 내용을 포함하는 조치를 이행해야 합니다.

| 구분 | 주요 내용 |
|------|-----------|
| 1. 위험관리방안 | 위험관리방안의 수립ㆍ운영 |
| 2. 설명 방안 | 기술적으로 가능한 범위에서 인공지능이 도출한 최종 결과, 결과 도출에 활용된 주요 기준, 학습용데이터의 개요 등에 대한 설명 방안의 수립ㆍ시행 |
| 3. 이용자 보호 | 이용자 보호 방안의 수립ㆍ운영 |
| 4. 사람의 감독 | 고영향 인공지능에 대한 사람의 관리ㆍ감독 방안 수립ㆍ운영 |
| 5. 문서화 | 안전성ㆍ신뢰성 확보를 위한 조치의 내용을 확인할 수 있는 문서의 작성과 보관 |
| 6. 그 밖의 사항 | 그 밖에 안전성ㆍ신뢰성 확보를 위하여 국가인공지능위원회에서 심의ㆍ의결된 사항 |

📌 **참고**: 이 조항은 사업자에게 투명성(설명 방안), 책임성(위험관리, 문서화), 그리고 인간 중심의 통제(사람의 관리·감독) 등 인공지능 윤리 원칙을 실질적으로 이행할 의무를 부여합니다.

#### 3. 이행 근거의 보관 및 공개 (제34조제2항)
- 고영향 인공지능사업자는 제1항에 따른 조치를 이행하고 그 근거를 문서로 보관해야 합니다.
- 또한, 위험관리방안의 주요 내용 등을 홈페이지 등에 게시하여 이용자가 쉽게 확인할 수 있도록 해야 합니다.

## 인공지능 안전성 기초

인공지능 안전성은 인공지능 시스템이 의도한 대로 작동하고, 안전하게 유지되며, 인간의 가치와 일치하도록 보장하기 위한 방법, 절차, 프레임워크를 포괄합니다. 주요 내용은 다음과 같습니다:

- 의도하지 않은 동작과 유해한 결과 방지
- 적대적 입력에 대한 견고성 보장
- 악의적인 공격에 대한 시스템 보안 유지
- 프라이버시 보존 및 민감한 데이터 보호
- 인공지능 결정에서의 투명성과 설명 가능성 제공

## 신뢰성 확보 방법

인공지능 시스템이 신뢰할 수 있도록 하기 위해 조직은 다음과 같은 다양한 방법을 구현합니다:

- 다양한 데이터셋과 시나리오에 걸친 엄격한 테스트
- 운영 환경에서의 지속적인 모니터링 및 검증
- 이중화 및 장애 안전 메커니즘
- 모델의 정기적인 업데이트 및 재학습
- 적용 가능한 경우 공식 검증 기법

## 인공지능 검증 및 인증

인공지능 시스템의 인증에는 다음이 포함됩니다:

- 정의된 기준에 대한 시스템 성능 평가
- 안전 기준 준수 여부 검증
- 윤리적 및 법적 요구사항 검증
- 교육 데이터 및 모델 동작 감사
- 개발 프로세스 및 통제 조치 문서화