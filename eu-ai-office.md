# EU AI 사무국 (AI Office)의 AI 안전 연구 관련 내용

**EU AI 사무국(AI Office)**은 **EU AI 법(AI Act)**에 따라 설립되었으며, 특히 범용 인공지능(GPAI) 모델과 관련된 **AI 안전 및 안보(Safety and Security)**를 감독하고 규제를 집행하는 핵심 기관입니다. 이 사무국은 AI 안전 연구를 직접 수행하고 국제적으로 조율하는 중요한 역할을 맡고 있습니다.

## 1. AI 사무국의 주요 역할 및 연구 중점

AI 사무국은 AI 법의 GPAI 관련 조항을 중심으로 AI 안전 연구 및 평가 활동을 진행합니다.

- **GPAI 모델 평가 및 분류**: 시스템적 위험을 초래할 수 있는 강력한 GPAI 모델을 식별하고 분류하며, 이 모델들이 AI 법의 안전 요구 사항을 충족하는지 평가하는 방법론을 연구합니다.

- **표준 및 기술 지침 개발**: GPAI 모델 제공자가 따라야 할 기술적 방법, 표준, 프로토콜을 개발하여, 모델의 투명성, 견고성, 안전성을 확보하도록 지원합니다. 이는 EU AI 법의 이행을 위한 핵심입니다.

- **위험 식별 및 완화**: 새로운 AI 기술, 특히 첨단 AI 모델에서 발생하는 **잠재적 위험(Emerging Risks)**을 조기에 식별하고, 이에 대응하기 위한 완화 전략 및 보호 장치(Safeguards) 연구를 수행합니다.

## 2. 연구를 위한 협력 체계 구축

AI 사무국은 내부 연구 역량 외에도, 국제적 및 학계와의 광범위한 협력을 통해 AI 안전에 대한 연구 결과를 확보하고 공론화합니다.

### 과학 자문 포럼 (Scientific Advisory Forum):

- AI 안전 연구 분야의 최고 전문가들로 구성된 포럼을 운영하여, 첨단 AI 모델의 능력, 잠재적 위험, 안전 기준 등에 대해 독립적인 과학적 조언을 받습니다. 이 포럼은 AI 사무국의 정책 결정과 연구 방향에 중요한 기초를 제공합니다.

### 국제 협력 (Global Cooperation):

- 미국, 영국 등 주요 국가의 AI 안전 연구소(AISI) 및 관련 국제 기구와 협력하여, AI 안전 평가 방법론과 표준을 조율하고 글로벌 AI 거버넌스에 기여합니다. 특히, 모델의 오용 및 통제력 상실과 관련된 연구 결과를 공유합니다.

### AI 안전 및 투명성을 위한 실무 그룹:

- GPAI 모델 안전 실무 그룹과 투명성 실무 그룹을 구성하여, 모델 개발사와 학계, 시민 사회의 전문가들이 참여하는 협력적 연구 환경을 조성하고 실질적인 기술적 해법을 모색합니다.

## 3. 연구 결과의 법적 적용

AI 사무국의 연구 결과는 단순한 권고에 그치지 않고, AI 법의 집행을 위한 구속력 있는 결정의 근거가 됩니다.

- **GPAI 위험 기준**: AI 사무국은 연구를 통해 확보한 최신 정보를 바탕으로, 특정 GPAI 모델이 시스템적 위험을 수반하는지 판단하는 **구체적인 임계값(Thresholds)**과 기준을 설정합니다.

- **표준화된 평가 프로토콜**: GPAI 모델 제공자가 모델을 시장에 출시하기 전에 수행해야 하는 모델 평가(Evaluation) 및 레드팀(Red Teaming) 활동에 대한 표준화된 프로토콜을 연구하고 발표합니다.

## 키워드
- EU AI 사무국
- AI Office
- EU AI 법
- AI Act
- GPAI
- 범용 인공지능
- AI 안전
- AI 안보
- 시스템적 위험
- 과학 자문 포럼
- 국제 협력
- AISI
- AI 거버넌스
- 잠재적 위험
- 보호 장치
- 모델 평가
- 레드팀
- 표준화
- 투명성
- 견고성
- 통제력 상실
- AI 법 집행
- 위험 식별
- 위험 완화
- AI 윤리
- AI 규제