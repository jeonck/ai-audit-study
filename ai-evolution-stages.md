# AI 시스템의 진화 방향과 단계별 인증, 표준, 사례

AI 시스템의 진화 단계를 소프트웨어 통합, 딥러닝 최적화, 생성형 AI 전문가 시스템, AI 에이전트 자율 시스템으로 구분하고, 각 단계에 요구되는 주요 인증/표준 및 구체적인 사례를 추가하여 모델과 위험 요소를 정리했습니다.

## 1. 융합의 단계: 소프트웨어 통합 (Software Integration)

AI가 기존 IT 시스템의 모듈로 통합되어 특정 기능을 지원합니다.

| 분류 | 모델 특성 및 역할 | 인증/표준 | 위험 요소 |
|------|-------------------|----------|-----------|
| **모델** | 전통적인 머신러닝 분류기, 초기 챗봇 (RPA 연계) | **ISO/IEC 27001**: 정보보호 경영 시스템 (IT 인프라 및 데이터 보안 확보) | 레거시 시스템과의 충돌, AI 기능 모듈의 초기 데이터 편향성, 단순한 오류율 문제 |
| **역할** | 이메일 스팸 분류, 간단한 데이터 입력 자동화, IT 시스템 내 기본적인 예측 기능 | **ISO 9001**: 품질 경영 시스템 (AI 통합 과정의 안정적 품질 확보) | 데이터 접근 통제: 기존 소프트웨어 내 민감 정보에 대한 AI 모듈의 무분별한 접근 및 통제 문제 |
| **사례** | CRM 시스템 내 단순 고객 문의 분류 기능, ERP 시스템 내 재고 수요 예측 (선형 회귀 등) | **SP(Software Process) 인증**: 소프트웨어 개발 프로세스 표준 준수 | AI 윤리 및 공정성 문제: 파급력은 낮으나, 초기에 잘못된 데이터로 인한 결과 왜곡 시작 |

## 2. 최적화의 단계: 딥러닝 기반 최적화 (Deep Learning Optimization)

복잡한 신경망을 통해 시스템의 성능과 효율을 극대화하며, AI가 핵심 제어 역할을 수행하기 시작합니다.

| 분류 | 모델 특성 및 역할 | 인증/표준 | 위험 요소 |
|------|-------------------|----------|-----------|
| **모델** | 강화 학습(RL), 심층 신경망(DNN) 기반의 예측 및 제어 모델 | **ISO 26262**: 자동차 기능 안전 표준 (자율주행 제어 시스템 적용) | 설명 가능성 부족 (Black Box): 오류 발생 시 원인 추적이 어려워 사고 대응 및 책임 소재 규명이 난해함 |
| **역할** | 리소스 분배 최적화, 공급망 관리, 이미지/음성 인식, 복잡한 공정 제어 | **ISO/IEC 42001**: AI 경영 시스템 (AI 관련 위험 관리 및 통제 요구) | 적대적 공격 취약성: AI 모델 자체의 취약점을 이용한 공격으로 인해 시스템의 의도치 않은 오작동 발생 |
| **사례** | 데이터센터 전력 효율 최적화 (Google), 공장 내 지능형 품질 검사 시스템, 교통 흐름 최적화 시스템 | **IEC 61508**: 전기/전자/프로그래밍 가능 전자 시스템의 기능 안전 표준 (산업 제어 시스템 적용) | 데이터 품질 및 편향성: 대규모 학습 데이터의 편향이 최적화 결과에 심각한 왜곡을 초래 |

## 3. 지식 확장 단계: 생성형 AI 기반 전문가 시스템 (Generative AI-based Expert Systems)

LLM의 추론 및 생성 능력을 활용하여 전문 지식 기반의 새로운 콘텐츠와 해결책을 제시합니다.

| 분류 | 모델 특성 및 역할 | 인증/표준 | 위험 요소 |
|------|-------------------|----------|-----------|
| **모델** | LLM 기반 챗봇, RAG(검색 증강 생성) 시스템, Code Generation 도구 | **EU AI Act (고위험 분류) 요구 사항**: 투명성, 인간 감독, 정확성 확보 | 환각 (Hallucination) 위험: AI가 사실이 아닌 정보를 그럴듯하게 생성하여 전문적 오류를 유발할 위험 (특히 법률, 의료 등) |
| **역할** | 전문 지식 기반 질의응답, 보고서 초안/법률 문서 초안 작성, 복잡한 문제 해결 아이디어 제시 | **NIST AI RMF**: 투명성, 설명 가능성, 공정성 특성 측정 및 관리 | 오정보 및 가짜 정보 확산: 딥페이크, 조작된 보고서 등 생성 결과물의 악용 위험 증대 |
| **사례** | 기업 내 지식 검색 및 요약 시스템, 개발자를 위한 자동 코드 완성 도구 (Copilot), 고객 서비스용 고도화된 상담 에이전트 | **AI 윤리 가이드라인 준수**: 한국의 국가AI 윤리 가이드라인 등 각국 윤리 지침 준수 의무 | 지적 재산권 및 저작권: 생성된 결과물이 학습 데이터를 침해하거나 표절할 위험 |

## 4. 자율성 확보 단계: AI 에이전트 기반 자율 시스템 (AI Agent-based Autonomous Systems)

AI가 스스로 목표를 설정, 계획하며 물리적/디지털 환경에서 인간의 개입 없이 복잡하고 장기적인 임무를 수행합니다.

| 분류 | 모델 특성 및 역할 | 인증/표준 | 위험 요소 |
|------|-------------------|----------|-----------|
| **모델** | 멀티모달 인식, 자율 계획 LLM, 강화 학습 기반의 행동 제어 시스템 (피지컬 AI) | **ISO 21448 (SOTIF)**: 안전을 위한 의도된 기능의 안전성 (자율주행차의 통제력 상실 방지) | 통제력 상실 (Loss of Control): AI의 자율적 행동이 인간의 의도와 벗어나 예측 불가능한 결과를 초래할 시스템적 위험 |
| **역할** | 공장 전체의 자율 운영, 휴머노이드 로봇을 통한 범용 작업 수행, 자율 사이버 방어/공격 시스템 | **EU AI Act (GPAI 요구 사항)**: 시스템적 위험 평가, 모델 안전성 테스트 및 보고 의무 | 책임 소재의 모호성: 에이전트의 자율적 결정으로 인한 사고 발생 시 법적, 윤리적 책임 소재 규명이 극히 어려움 |
| **사례** | 레벨 4/5 자율주행차, 첨단 무인 공장 운영 시스템, 피지컬 AI(휴머노이드)를 이용한 물류/제조 작업 | **국제 안보 협약 및 통제 (G7 등)**: AI의 군사적 오용 및 이중 용도 기술 확산 방지 | 비상 정지 및 복구: AI가 통제 불능 상태에 빠졌을 때 안전하게 시스템을 정지시키고 복구할 수 있는 메커니커즘의 부재 |

## 키워드
- 인공지능
- 진화 단계
- 소프트웨어 통합
- 딥러닝 최적화
- 생성형 AI 전문가 시스템
- AI 에이전트 자율 시스템
- AI 인증
- AI 표준
- ISO/IEC 27001
- ISO 9001
- ISO 26262
- ISO/IEC 42001
- IEC 61508
- EU AI Act
- NIST AI RMF
- SOTIF
- 위험 요소
- 설명 가능성
- 환각
- 오정보
- 통제력 상실
- 자율 시스템