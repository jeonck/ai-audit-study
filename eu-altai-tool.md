# EU ALTAI (Assessment List for Trustworthy AI) 자체 점검 도구

EU의 **신뢰할 수 있는 AI 평가 목록(Assessment List for Trustworthy AI, ALTAI)**은 2019년 **AI 고위 전문가 그룹(HLEG)**이 발표한 **'신뢰할 수 있는 AI를 위한 윤리 가이드라인'**의 7가지 핵심 요구사항을 실질적으로 구현하고 자체 점검할 수 있도록 개발된 체크리스트 형태의 도구입니다.

ALTAI는 법적 구속력은 없지만, AI 시스템의 개발 및 배포 과정에서 윤리적 고려 사항과 신뢰성을 체계적으로 평가하고 문서화하는 데 활용됩니다.

## ALTAI 자체 점검 도구의 구조 및 목적

### 1. 주요 목적

- **실무 지침 제공**: 추상적인 윤리 원칙을 개발자, 배포자, 사용자가 이해하고 적용할 수 있는 구체적인 질문과 항목으로 변환합니다.

- **리스크 평가**: AI 시스템의 전 수명 주기에 걸쳐 잠재적인 윤리적, 규제적 위험을 자체적으로 식별하고 문서화하도록 돕습니다.

- **신뢰성 확보**: 7가지 핵심 요구사항(7 Key Requirements)을 충족함으로써, 시스템의 **신뢰성(Trustworthiness)**을 체계적으로 향상시킵니다.

### 2. 7가지 핵심 요구사항 기반

ALTAI는 7가지 요구사항을 기반으로 하며, 각 요구사항은 수많은 하위 질문과 확인 사항으로 구성되어 있습니다.

| 요구사항 (Requirement) | ALTAI 점검 목표 (Checklist Focus) |
|------------------------|-----------------------------------|
| **1. 인간의 주도성 및 감독** | 인간 통제권(Human-in-command), 비상 시 정지 메커니즘, 인간의 개입 수준의 적절성. |
| **2. 기술적 견고성 및 안전성** | 시스템의 정확도, 신뢰성, 재현성 확보, 적대적 공격에 대한 방어 능력. |
| **3. 프라이버시 및 데이터 거버넌스** | GDPR 준수, 데이터 품질, 데이터 수집의 적법성, 편향 완화 조치. |
| **4. 투명성** | AI 모델의 설명 가능성(Explainability), 시스템의 추적성(Traceability), 사용자에 대한 명확한 의사소통. |
| **5. 다양성, 비차별 및 공정성** | 차별 금지 원칙 준수, 데이터 및 모델의 편향 점검, 다양한 사용자 그룹에 대한 접근성. |
| **6. 사회적 및 환경적 웰빙** | 시스템이 사회적, 민주적, 환경적 가치에 미치는 긍정적 및 부정적 영향 평가. |
| **7. 책임성** | AI 시스템 결과에 대한 책임 주체 명시, 내부/외부 감사 가능성 및 보고 체계. |

### 3. ALTAI 자체 점검의 실제 예시 (투명성)

ALTAI는 각 요구사항별로 예/아니오 또는 문서화 확인 등의 구체적인 질문을 던집니다.

| 점검 영역 | 예시 질문 (ALTAI Style) |
|-----------|--------------------------|
| **시스템 작동 설명** | 시스템의 목적, 작동 방식, 성능 한계가 최종 사용자에게 명확하게 전달되는가? |
| **설명 가능성** | 시스템의 결정에 대한 주요 요인(Contributing Factor)이 해당 결정의 수용자에게 이해하기 쉬운 형태로 제공되는가? |
| **데이터 추적성** | AI 모델 훈련에 사용된 데이터 소스, 데이터 처리 과정, 라이선스 정보가 문서화되어 쉽게 추적될 수 있는가? |
| **시스템 변경** | 배포된 모델이 업데이트되거나 재훈련될 때마다 그 변경 사항이 문서화되고 추적되는가? |

### 4. EU AI 법과의 관계

ALTAI는 **EU AI 법(AI Act)**의 출시에 따라 그 중요성이 더욱 커졌습니다. AI 법은 고위험 AI 시스템에 대해 강제적인 위험 관리 시스템(Risk Management System) 및 품질 경영 시스템을 요구하는데, ALTAI의 점검 항목들은 이러한 법적 의무를 충족하기 위한 실무적인 준비 단계와 문서화의 기초 자료로 활용될 수 있습니다.

## 7가지 핵심 요구사항별 ALTAI 점검 포인트

**EU의 신뢰할 수 있는 AI 평가 목록(ALTAI)**은 AI 시스템의 윤리적 및 기술적 신뢰성을 보장하기 위해 고안된 자체 점검 도구입니다. 이 도구는 **'신뢰할 수 있는 AI를 위한 윤리 가이드라인'**에 명시된 7가지 핵심 요구사항을 기준으로, 조직이 실무에서 점검해야 할 구체적인 포인트를 제시합니다.

### 1. 인간의 주도성 및 감독 (Human Agency and Oversight) 🧍

**목표**: AI 시스템이 자율적으로 운영되더라도, 인간이 항상 최종적인 통제권을 유지하고, AI의 부정적인 영향을 피할 수 있도록 보장합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **인간 통제권(Human-in-Command)** | 인간이 AI 시스템의 결정을 **무시(override)**하거나 **중단(deactivate)**할 수 있는 명확한 절차가 있는가? |
| **감독 및 역할** | AI 시스템의 운영에 대한 인간의 책임과 개입 수준이 명확하게 정의되어 있는가? (예: Human-in-the-Loop, Human-on-the-Loop) |
| **비상 및 복구** | 시스템 오류 또는 예상치 못한 작동 시 **안전 모드(Safe Mode)**로 전환하거나, 자동 복구가 가능한가? |
| **사용자의 권리** | 사용자가 AI 결정에 대해 이의를 제기하고 구제(Redress) 받을 수 있는 메커니즘이 마련되어 있는가? |

### 2. 기술적 견고성 및 안전성 (Technical Robustness and Safety) ⚙️

**목표**: AI 시스템이 신뢰할 수 있고, 안전하며, 의도하지 않은 해(Harm)를 끼치지 않고, 다양한 환경에서 일관되게 작동하도록 보장합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **정확성 및 신뢰성** | 시스템의 정확도, 정밀도, 재현성 등 핵심 성능 지표가 특정 목적에 적합한 수준으로 측정되고 문서화되어 있는가? |
| **안전성** | 시스템이 사람이나 환경에 해를 끼칠 수 있는 잠재적 위험을 식별하고 완화하기 위한 테스트 및 검증 절차를 거쳤는가? |
| **강건성(Robustness)** | 데이터 노이즈, 분포 변화(Drift), 또는 적대적 공격과 같은 예외적 입력에 대해 시스템이 안정적으로 대응하는가? |
| **복원력(Resilience)** | 시스템 실패 시 중요 기능의 **가용성(Availability)**을 유지하기 위한 백업 및 복구 계획이 있는가? |

### 3. 프라이버시 및 데이터 거버넌스 (Privacy and Data Governance) 🔐

**목표**: AI 시스템에 사용되는 데이터가 개인정보보호 규정을 준수하고, 데이터의 품질 및 무결성이 확보되도록 관리합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **데이터 품질** | 학습 및 테스트 데이터의 정확성, 완전성, 일관성이 보장되는가? |
| **데이터 사용의 적법성** | 데이터 수집 및 처리가 GDPR 등 관련 개인정보보호 법률을 준수하며, 명시적인 동의를 받았는가? |
| **프라이버시 보장** | 설계에 의한 프라이버시(Privacy by Design) 원칙이 적용되었으며, 데이터 익명화 및 가명화 조치가 적절한가? |
| **데이터 접근 및 보안** | AI 시스템 데이터에 대한 접근 통제(Access Control) 및 보안 조치가 구현되어 있는가? |

### 4. 투명성 (Transparency) 💡

**목표**: AI 시스템의 작동 방식, 결정 과정, 데이터 사용 등에 대한 정보가 명확하고 접근 가능한 방식으로 이해관계자에게 전달되도록 합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **설명 가능성(Explainability)** | AI 시스템의 결정 근거와 **입력 요인(Feature Importance)**이 사용자가 이해할 수 있는 방식으로 제공되는가? |
| **시스템 투명성** | AI 시스템이 특정 임무를 수행하고 있다는 사실, 그리고 그 목적 및 한계가 사용자에게 명확히 전달되는가? |
| **추적성(Traceability)** | AI 모델의 개발 과정, 훈련 데이터, 버전 관리, 변경 이력 등이 감사(Audit) 가능한 형태로 문서화되어 있는가? |
| **소통 및 공개** | AI 시스템의 잠재적 위험 및 의도치 않은 결과가 이해관계자에게 적절히 공개되었는가? |

### 5. 다양성, 비차별 및 공정성 (Diversity, Non-discrimination and Fairness) ⚖️

**목표**: AI 시스템이 모든 사용자 및 집단에게 공정하게 작동하고, 불법적인 편향이나 차별을 야기하지 않도록 설계합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **편향 식별 및 완화** | 훈련 데이터와 AI 모델에서 성별, 인종, 연령 등 보호되는 속성(Protected Attributes)에 대한 편향이 체계적으로 식별되었는가? |
| **그룹별 공정성** | 다양한 인구 통계학적 그룹 또는 이해관계자 그룹에 대해 시스템의 **성능 지표(예: 정확도, 오류율)**가 공정하게 유지되는가? |
| **접근성** | AI 시스템이 장애가 있거나 소외된 사용자를 포함한 다양한 사용자에게 접근 가능하도록 설계되었는가? |
| **포용성** | AI 시스템 개발 팀의 구성에 다양성이 반영되어, 다양한 관점이 설계에 통합되었는가? |

### 6. 사회적 및 환경적 웰빙 (Societal and Environmental Well-being) 🌍

**목표**: AI 시스템이 사회에 긍정적인 영향을 미치고, 환경적 지속 가능성에 기여하도록 설계하고 배포합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **사회적 영향 평가** | AI 시스템이 민주주의, 사회적 조화, 노동 환경, 인권 등에 미치는 긍정적 및 부정적 영향을 사전에 평가했는가? |
| **환경 영향 평가** | AI 모델 훈련 및 운영에 필요한 에너지 소비 및 컴퓨팅 자원이 평가되었고, 가능한 경우 지속 가능한 솔루션이 모색되었는가? |
| **악용 방지** | AI 시스템이 의도하지 않은 악용이나 **사회적 조작(Manipulation)**에 사용될 가능성을 평가하고 완화 조치를 마련했는가? |

### 7. 책임성 (Accountability) 🤝

**목표**: AI 시스템의 결과에 대한 책임이 명확하며, 시스템의 작동 과정을 평가하고 감사할 수 있는 거버넌스 체계를 구축합니다.

| 점검 포인트 | 세부 내용 |
|-------------|------------|
| **책임 주체 명확화** | AI 시스템의 각 단계(데이터 수집, 모델 개발, 배포 등)에 대한 책임 있는 주체와 역할이 명확히 정의되어 있는가? |
| **감사 가능성** | AI 시스템의 설계 결정, 데이터 세트, 모델 성능 및 위험 평가 문서가 정기적인 내부/외부 감사를 위해 준비되어 있는가? |
| **거버넌스 구조** | AI 윤리 위원회 또는 유사한 내부 거버넌스 구조가 AI 시스템의 개발 및 운영을 감독하는가? |
| **피해 보고 및 구제** | AI 시스템으로 인해 발생한 피해에 대해 보고하고 적절한 구제 조치를 취할 수 있는 절차가 있는가? |

ALTAI는 이러한 질문들을 통해 조직이 AI 법에서 요구하는 위험 관리 및 품질 시스템의 필수 요건을 자체적으로 점검하고, 윤리적 AI 거버넌스를 구축하는 데 핵심적인 역할을 합니다.

## 키워드
- EU ALTAI
- Assessment List for Trustworthy AI
- 신뢰할 수 있는 AI
- 윤리 가이드라인
- HLEG
- 7가지 핵심 요구사항
- 인간의 주도성
- 기술적 견고성
- 프라이버시
- 데이터 거버넌스
- 투명성
- 설명 가능성
- 다양성
- 비차별
- 공정성
- 사회적 웰빙
- 환경적 웰빙
- 책임성
- GDPR
- AI 법
- AI Act
- 고위험 AI
- 위험 관리
- 자체 점검 도구
- 윤리적 AI
- AI 거버넌스
- Human-in-the-Loop
- Human-on-the-Loop
- 편향 완화
- 데이터 품질
- 접근성
- 감사 가능성
- 설명 가능성
- XAI