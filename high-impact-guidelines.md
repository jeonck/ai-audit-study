# 고영향 인공지능 판단 가이드라인(안)

과학기술정보통신부(과기정통부)는 **인공지능 발전과 신뢰 기반 조성 등에 관한 기본법(AI 기본법)**의 2026년 1월 시행에 앞서, 기업들이 법적 의무를 이행할 수 있도록 **'고영향 인공지능 판단 가이드라인(안)'**을 발표하고 하위법령 제정 방향을 구체화했습니다. 📜

이 가이드라인(안)은 AI 사업자가 자신이 제공하는 AI 시스템이 고영향 인공지능에 해당하는지 여부를 스스로 판단하고 예측 가능성을 높일 수 있도록 구체적인 기준과 절차를 제시하는 것이 목적입니다.

## 고영향 AI 판단의 2단계 체계

AI 기본법에 따른 고영향 인공지능은 ① 특정 영역에서 활용되고 ② 사람의 생명·신체 안전 및 기본권에 중대한 영향을 미칠 우려가 있는 AI 시스템을 의미합니다. 가이드라인은 이 정의를 바탕으로 2단계의 판단 절차를 제시합니다.

### 1단계: 10대 활용 영역 확인

먼저, AI 시스템이 AI 기본법 제2조 제4호 각 목에서 정한 다음 10개 영역 중 하나에서 활용되는지 확인합니다.

| 분류 | 주요 활용 영역 |
|------|---------------|
| 생명/신체 안전 | 보건의료 (디지털의료기기, 비의료 건강관리 서비스 포함), 에너지/수도 공급, 교통시설 운영 (자율주행, 차량 내 주요 시스템) |
| 기본권/권리 | 공공 서비스 (자격 확인, 의사 결정), 범죄 수사·체포 업무를 위한 생체인식 분석·활용, 채용, 대출 심사 등 개인의 권리·의무에 중대한 영향을 미치는 판단 |
| 기타 | 학생 평가 등 |

### 2단계: '중대한 영향' 여부 판단

1단계 영역에 해당하더라도, 그 AI 시스템이 **'중대한 영향을 미치거나 위험을 초래할 우려'**가 있는지를 판단합니다. 가이드라인은 이 중대성을 판단하기 위해 다음과 같은 5가지 세부 고려 사항을 제시합니다.

1. **기능 중요도**: AI 시스템이 기능하는 대상(인체, 차량, 시설 등)에 필수적인 기능을 독립적으로 수행하는 정도.
2. **자율성 및 개입 여부**: AI 시스템이 자율적으로 의사 결정을 내리는 정도와 사람의 실질적 관리·감독이 가능한지 여부.
3. **영향력의 크기**: AI 시스템의 오류 발생 시 피해 규모 (인명 피해, 차별 발생, 금융 계약 파기 등) 및 피해의 회복 가능성 정도.
4. **민감 정보 활용**: AI가 민감한 개인정보를 사용하거나 차별적·편향적 데이터를 사용하는지 여부.
5. **예외 사항**: 법적 예외(국방/국가안보)나 피해자 수색 등 공익적 목적이 있는 경우.

## 주요 영역별 고영향 판단 사례 (안)

가이드라인(안)은 기업의 예측 가능성을 높이기 위해 주요 영역별로 고영향 AI에 해당하는 구체적인 사례를 제시하고 있습니다.

| 영역 | 고영향으로 분류되는 주요 사례 |
|------|-----------------------------|
| 보건의료 | AI 의사 결정이 환자의 생명·신체·정신에 중대한 피해를 초래할 경우. (예: 진단 오류로 치명적 결과 초래) |
| 범죄 수사 | CCTV·인터넷에서 무작위 안면 이미지 수집·인식, 인종·신체적 특징을 추론·분류하는 대량 감시. 인간 검토 없이 AI 결과만으로 범인 여부를 결정하는 경우. |
| 채용 심사 | AI 결과가 채용 여부에 실질적으로 영향을 미치고, 정당한 권한을 가진 사람의 실질적 개입이 없는 경우. |
| 대출 심사 | AI가 대출 심사 과정에서 최종 결정에 상당한 영향을 미치거나 차별적·민감한 데이터를 사용하는 경우. |
| 자율주행 | AI가 스스로 주행 의사결정을 내리고, 사고 시 인명 피해 가능성이 큰 자율주행 시스템. |

## 기업이 이행해야 할 주요 책무

AI 시스템이 고영향 AI로 판단되면, 해당 사업자는 AI 기본법 제34조에 따라 다음과 같은 강화된 안전성 및 신뢰성 확보 조치를 이행해야 합니다.

- 위험관리방안 수립·운영
- 기술적으로 가능한 범위에서 설명 방안 수립·시행 (결과, 주요 기준, 학습용 데이터 개요 등)
- 이용자 보호 방안 수립·운영
- 고영향 AI에 대한 사람의 관리·감독 방안 수립·운영
- 조치 내용을 확인할 수 있는 문서의 작성과 보관

이 가이드라인은 규제보다는 예방적 장치로서, 기업이 스스로 AI 위험을 진단하고 대응하여 국민 기본권을 보호하고 AI 신뢰성을 확보하도록 돕는 데 중점을 두고 있습니다.